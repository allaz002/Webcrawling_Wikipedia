
[CRAWLER]
# Webseiten Beschränkung
SEED_URLS = https://de.wikipedia.org/wiki/Wikipedia:Hauptseite
ALLOWED_DOMAINS = de.wikipedia.org
IGNORED_NAMESPACES = Benutzer:, Datei:, Spezial:, Kategorie:, Hilfe:, Diskussion:, Vorlage:, Portal:, MediaWiki:
# Abbruchbedingungen
MAX_PAGES = 1000
MAX_RELEVANT_PAGES = 1000
MAX_RUNTIME_MINUTES = 30
# Allgemeine Crawlingeinstellungen
BATCH_SIZE = 32
FRONTIER_MAX_SIZE = 10000
RELEVANCE_THRESHOLD = 0.15

[WEIGHTS]
# Verhältnis Link- und Elterndokumentgewichtung
LINK_WEIGHT = 0.334
PARENT_WEIGHT = 0.666
# Verhältnis aus Titel-, Überschrift- und Paragraphgewichtung
TITLE_WEIGHT = 0.25
HEADING_WEIGHT = 0.25
PARAGRAPH_WEIGHT = 0.50

[KEYWORD]
KEYWORDS =
    intelligenz, künstlich, künstliche, artificial, intelligence, algorithmus, algorithmen, algorithm, learning, machine, maschinell, maschinelles, lernen, deep, neural, neuronale,
    neuronales, netz, netze, network, networks, training, trainieren, modell, modelle, model, models, daten, data, dataset, datasets, klassifikation, classification, regression, clustering,
    supervised, unsupervised, reinforcement, überwacht, unüberwacht, verstärkung, verstärkungslernen, tensorflow, pytorch, keras, scikit, sklearn, python, numpy, pandas, jupyter, colab, gpu,
    tpu, tensor, tensoren, gradient, gradienten, backpropagation, optimizer, optimierung, optimization, loss, accuracy, precision, recall, f1, score, validation, kreuzvalidierung, overfitting,
    underfitting, regularisierung, dropout, batch, epoch, iteration, layer, schicht, schichten, hidden, versteckt, activation, aktivierung, sigmoid, relu, softmax, tanh, pooling, convolution,
    cnn, rnn, lstm, gru, transformer, bert, gpt, nlp,cv, vision, computer, bildverarbeitung, bilderkennung, objekterkennung, segmentierung, detection, recognition, spracherkennung, sprachverarbeitung,
    chatbot, robotik, automation, automatisierung, ethik, bias, fairness, explainable, interpretierbar, kaggle, benchmark, dataset
# Mindestanzahl Keywords für Relevanz
ANCHOR_MIN_KEYWORDS = 1
TITLE_MIN_KEYWORDS = 1
HEADING_MIN_KEYWORDS = 1
PARAGRAPH_MIN_KEYWORDS = 2

[VECTORSPACE]
# Vectonizer Einstellungen
NGRAM_MIN = 1
NGRAM_MAX = 2
MIN_DF = 2
MAX_DF = 0.90
MAX_FEATURES = 5000
# Trainigsdaten Verteilung
IDF_RATIO_IRRELEVANT = 0.50
IDF_RATIO_MODERATE = 0.35
IDF_RATIO_RELEVANT = 0.15
# Pfadeinstellungen
MODEL_PATH = models/vectorspace_model.pkl
VECTORIZER_PATH = models/vectorspace_vectorizer.pkl
TRAINING_DATA_PATH = training_data/training_samples.json


[NAIVEBAYES]
# Vectonizer Einstellungen
NGRAM_MIN = 1
NGRAM_MAX = 2
MIN_DF = 2
MAX_DF = 0.90
MAX_FEATURES = 2500
# Pfadeinstellungen
MODEL_PATH = models/naive_bayes_model.pkl
VECTORIZER_PATH = models/naive_bayes_vectorizer.pkl
TRAINING_DATA_PATH = training_data/training_samples.json

[PLOTTING]
CREATE_PLOTS = True
OUTPUT_DIRECTORY = plots
time_base_pages = 100
venn_top_percent = 10
table_items_per_block = 5

[SCRAPY]
USER_AGENT = TopicalCrawler/1.0 (+http://example.com/bot)
ROBOTSTXT_OBEY = True
CONCURRENT_REQUESTS = 2
DOWNLOAD_DELAY = 0.5
AUTOTHROTTLE_ENABLED = True
AUTOTHROTTLE_START_DELAY = 0.5
AUTOTHROTTLE_MAX_DELAY = 3.0
AUTOTHROTTLE_TARGET_CONCURRENCY = 2.0